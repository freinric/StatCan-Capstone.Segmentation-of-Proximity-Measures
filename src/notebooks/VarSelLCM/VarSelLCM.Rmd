---
title: "VarSelLCM"
author: "Avishek"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=TRUE, 
                      fig.align="center", 
                      fig.width=8, 
                      fig.height=6)
```

* * *

# Preliminary 

## Loading \& Cleaning Data

```{r}
set.seed(2023)
library(dplyr)
library(cluster)
library(ggplot2)
library(factoextra)
library(clusterCrit)
library(VarSelLCM)
library(clustertend)
load('../../../data/master_pms_df.Rdata')

# Convert selected columns to numeric
master <- master %>%
  mutate(PMS_DBPOP = as.numeric(gsub(",", "", PMS_DBPOP)), # Dissemination block population
         PMS_DAPOP = as.numeric(gsub(",", "", PMS_DAPOP)), # Dissemination area population
         PMS_CSDPOP = as.numeric(gsub(",", "", PMS_CSDPOP)), # Census subdivision population
         PMS_CMAPOP = as.numeric(gsub(",", "", PMS_CMAPOP)), # Census metropolitan area population
         PMS_PRPOP = as.numeric(gsub(",", "", PMS_PRPOP)), # Province or territory population
         # in_db_emp = as.numeric(in_db_emp),
         # in_db_pharma = as.numeric(in_db_pharma),
         # in_db_childcare = as.numeric(in_db_childcare),
         # in_db_health = as.numeric(in_db_health),
         # in_db_grocery = as.numeric(in_db_grocery),
         # in_db_educpri = as.numeric(in_db_educpri),
         # in_db_educsec = as.numeric(in_db_educsec),
         # in_db_lib = as.numeric(in_db_lib),
         # in_db_parks = as.numeric(in_db_parks),
         # in_db_transit = as.numeric(in_db_transit),
         PMS_prox_idx_emp = as.numeric(PMS_prox_idx_emp),
         PMS_prox_idx_pharma = as.numeric(PMS_prox_idx_pharma),
         PMS_prox_idx_childcare = as.numeric(PMS_prox_idx_childcare),
         PMS_prox_idx_health = as.numeric(PMS_prox_idx_health),
         PMS_prox_idx_grocery = as.numeric(PMS_prox_idx_grocery),
         PMS_prox_idx_educpri = as.numeric(PMS_prox_idx_educpri),
         PMS_prox_idx_educsec = as.numeric(PMS_prox_idx_educsec),
         PMS_prox_idx_lib = as.numeric(PMS_prox_idx_lib),
         PMS_prox_idx_parks = as.numeric(PMS_prox_idx_parks),
         PMS_prox_idx_transit = as.numeric(PMS_prox_idx_transit),
         DBUID = as.character(DBUID),
         PMS_DAUID = as.character(PMS_DAUID),
         PMS_CSDUID = as.character(PMS_CSDUID),
         PMS_CMAUID = as.character(PMS_CMAUID),
         PMS_CMAPUID = as.character(PMS_CMAPUID),
         PMS_PRUID = as.character(PMS_PRUID),
         PMS_suppressed = as.character(PMS_suppressed),
         PMS_transit_na = as.character(PMS_suppressed))


# Subset columns that start with "prox_idx"
amenities <- colnames(master)[grepl("^PMS_prox_idx", colnames(master))]
# master dataset - contains only proximity columns
master_amenities <- master[, amenities]
# variables to cluster with
clust_vars = c('CSD_AREA', 'PMS_CSDPOP', 'PMS_DBPOP', 'IOR_Index_of_remoteness') #, 'PMS_CMATYPE')

# subsampling data 
perc = 3 #percentage of data to subsample
subsample = (nrow(master)/100)*perc 
master_sample = master[sample(nrow(master), subsample),]

master_sample_wo_na <- na.omit(master_sample)

master_sample_log <- master_sample_wo_na

# log transform PMs
for (i in amenities){
  master_sample_log[,i] = log(master_sample_wo_na[,i])
}


```



```{r}
# cutoff values for all amenities
all_cutoffs = list()

#cutoff function
#https://stats.stackexchange.com/questions/586937/identify-the-point-of-intersection-from-two-distributions
cutoff = function(x, y){
  # Find global minimum and maximum
  xymin <- min(x,y)
  xymax <- max(x,y)
# Estimate densities
  dx <- density(x, n=512, from=xymin, to=xymax)
  dy <- density(y, n=512, from=xymin, to=xymax)

# Plot results
  #plot(dx, xlim=c(xymin, xymax), type="l", lwd=3, xlab="X", ylab="Density", main="")
  #lines(dy, col="red", lwd=3)

# Differences in densities
  dx$diff <- dx$y - dy$y
  ex <- NULL  # Store the intersection points
  ey <- NULL
  k = 0
  for (i in 2:length(dx$x)) {
      # Look for a change in sign of the difference in densities
      if (sign(dx$diff[i-1]) != sign(dx$diff[i])) {
         k = k + 1
         # Linearly interpolate
         ex[k] <- dx$x[i-1] + (dx$x[i]-dx$x[i-1])*(0-dx$diff[i-1])/(dx$diff[i]-dx$diff[i-1])
         ey[k] <- dx$y[i-1] + (dx$y[i]-dx$y[i-1])*(ex[k]-dx$x[i-1])/(dx$x[i]-dx$x[i-1])
         #lines(c(ex[k],ex[k]), c(0,ey[k])) #more plotting
         #points(ex[k], ey[k], pch=16, col="green" )
    }
  }
  exf = ex[ey > 0.5 & ex > 0.01]
  eyf = ey[ey > 0.5 & ex > 0.01]

  if (length(exf) > 1){
    #stop('More than one intersection above 0.5 detected! Change y-axis threshold.')
    exf = exf[1]
    eyf = eyf[1]
  }

  return(c(exf, eyf))
}

#mode function
Mode = function(x){
  ux = unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#print list items function for profiles
print_list = function(x, cl){
  df = as.data.frame(x)
  if (ncol(df) == 1){
    df = as.data.frame(t(df))
    row.names(df) = ''
  }
  names(df) = paste('Cluster', cl)
  print(df)
  cat('\n\n')
}
```

## Introduction



## Assumptions of the Alogrithm

VarselLCM assume that values are missing completely at random while using the model without imputing missing values. 

Algorithm steps:











```{r}
#algorithm function --> must return: data with no NAs, cluster assignments
algo = function(dataset, num=NULL){
  # set.seed(2023)
  sil_coefs = c()
  xie_coefs = c()
  dunn_coefs = c()
  counter = 1
  for (i in num){
    nr_cluster = i # number of clusters
    res = VarSelCluster(dataset, gvals=nr_cluster, nbcores = 4, vbleSelec = FALSE)
    
    # Obtain the cluster assignments from VarSelCluster
    cluster_assignments <- res@partitions@zMAP
    
    # Obtain the data from VarselCluster
    cluster_data <- res@data@dataContinuous@data
    
    sil_coefs[counter] = intCriteria(as.matrix(cluster_data), 
                                     as.integer(cluster_assignments), 
                                     'Silhouette')$silhouette
    
    xie_coefs[counter] = intCriteria(as.matrix(cluster_data), 
                                     as.integer(cluster_assignments), 
                                     'Xie_Beni')$xie_beni
    
    dunn_coefs[counter] = intCriteria(as.matrix(cluster_data), 
                                     as.integer(cluster_assignments), 
                                     'Dunn')$dunn
    counter = counter + 1
  }
  
  #plot silhouette coefficients
  plot(sil_coefs~num, type = 'l', ylab="Silhouette Coefficient", xlab='Number of Clusters', lwd=2)
  
  # plot Xie_Beni coefficients
  plot(xie_coefs~num, type = 'l', ylab="Xie_Beni Coefficient", xlab='Number of Clusters', lwd=2)
  
  # plot Dunn Index coefficients
  plot(dunn_coefs~num, type = 'l', ylab="Dunn Coefficient", xlab='Number of Clusters', lwd=2)
  
  res_sil_coefs <- num[which(sil_coefs == max(sil_coefs))]
  res_xie_coefs <- num[which(xie_coefs == min(xie_coefs))]
  res_dunn_coefs <- num[which(dunn_coefs == max(dunn_coefs))]
  
  # Find the most suggested number of clusters
  most_frequent <- Mode(c(res_sil_coefs, res_xie_coefs, res_dunn_coefs))
  
  #re-run algorithm with highest sil
  res = VarSelCluster(dataset, gvals=most_frequent, nbcores = 4, vbleSelec = FALSE) 
  
  return(list('complete_data' = res@data@dataContinuous@data, 'clusts' = res@partitions@zMAP))
}

```


```{r}
#master function
do_everything = function(dataset, amen_name, num){
  set.seed(2023)
  # remove NA values
  amen = dataset[!is.na(dataset[,amen_name]),]
  clust_data = dataset[!is.na(dataset[,amen_name]),c(amen_name, clust_vars)]
  
  # scale data
  for (i in clust_vars){
    clust_data[,i] = scales::rescale(clust_data[,i], to=c(0,1))
  }
  
  hopkins <- hopkins(clust_data, n = nrow(clust_data)-1)
  print(paste("Hopkins statistic:", hopkins$H))
  
  # algorithm
  res = algo(clust_data, num)

  
  # store cluster results
  clusts = res$clusts
  comp_data = res$complete_data
  rm(res)
  
  # re-assign clusters so that they're in order
  comp = list()
  for (i in unique(clusts)){
    temp = amen[clusts == i,amen_name]
    comp[[i]] = Mode(round(temp, 6))
  }
  if (max(unlist(comp)) == comp[[1]]){
    ord = match(comp, comp[order(unlist(comp))])
  } else{
    ord = match(comp[order(unlist(comp))], comp) 
  }
  clusts = ord[clusts]
  
  # plot
  pass = list(data = comp_data, cluster = clusts)
  plot(fviz_cluster(pass, ellipse.type = "norm") + theme_minimal())
  
  cutoffs = list()
  all_cutoffs = list()
  plot(density(amen[clusts == 1,amen_name]), xlim=c(0, 1), lwd=2, xlab="X", ylab="Density", main="")
  for (j in 1:(length(unique(clusts))-1)){
      cutoffs[[j]] = cutoff(amen[clusts == j,amen_name], amen[clusts == j+1,amen_name])
      all_cutoffs[[amen_name]][j] = cutoffs[[j]][1]
      lines(density(amen[clusts == j+1,amen_name]), col=(j+1), lwd=2)
      points(cutoffs[[j]][1], cutoffs[[j]][2], pch=16, col="green" )
  }

  print('Segment cutoff values:')
  for (a in 1:length(cutoffs)){
    print(cutoffs[[a]][1])
  }
  
  #silhouette plot
  sil = silhouette(clusts, dist(comp_data))
  plot(fviz_silhouette(sil))
  
  
  #profiles
  print('Cluster profiles:')
  profiles = list()
  for (k in sort(unique(clusts))){
    temp = dataset[clusts == k,]
    profiles[['Count']][k] = as.character(nrow(temp))
    profiles[['DB_population']][k] = round(mean(temp$PMS_DBPOP, na.rm = T), 1)
    profiles[['CSD_population']][k] = round(mean(temp$PMS_CSDPOP, na.rm = T), 1)
    profiles[['CMA_type']][[k]] = summary(temp$PMS_CMATYPE)
    profiles[['Index_of_Remoteness']][k] = round(mean(temp$IOR_Index_of_remoteness, na.rm = T), 3)
    profiles[['Provinces']][[k]] = summary(temp$PROVINCE)
    profiles[['Amenity_dense']][[k]] = summary(temp$PMS_amenity_dense)
  }
  #printing profiles
  print('Num of DBs:')
  print_list(profiles[['Count']], sort(unique(clusts)))
  cat('\n DB Population: \n')
  print_list(profiles[['DB_population']], sort(unique(clusts)))
  cat('\n CSD Population: \n')
  print_list(profiles[['CSD_population']], sort(unique(clusts)))
  cat('\n CMA Type: \n')
  print_list(profiles[['CMA_type']], sort(unique(clusts)))
  cat('\n Index of Remoteness: \n')
  print_list(profiles[['Index_of_Remoteness']], sort(unique(clusts)))
  cat('\n Provinces: \n')
  print_list(profiles[['Provinces']], sort(unique(clusts)))
  cat('\n Amenity dense: \n')
  print_list(profiles[['Amenity_dense']], sort(unique(clusts)))
  
  #return all_cutoff values
  return(all_cutoffs)
}
```





## Employment

```{r}
lst_emp = do_everything(master_sample_wo_na, 'PMS_prox_idx_emp', 2:6)
all_cutoffs_emp = append(all_cutoffs, lst_emp)
```

### Health 

```{r}
lst_health = do_everything(master_sample_wo_na, 'PMS_prox_idx_health', 2:6)
all_cutoffs_health = append(all_cutoffs, lst_health)
```


### Childcare 

```{r}
lst_childcare = do_everything(master_sample_wo_na, 'PMS_prox_idx_childcare', 2:6)
all_cutoffs_childcare = append(all_cutoffs, lst_childcare)
```


### Parks 

```{r}
lst_parks = do_everything(master_sample_wo_na, 'PMS_prox_idx_parks', 2:6)
all_cutoffs_parks = append(all_cutoffs, lst_parks)
```

### Education Primary 

```{r}
lst_educpri = do_everything(master_sample_wo_na, 'PMS_prox_idx_educpri', 2:6)
all_cutoffs_educpri = append(all_cutoffs_educpri, lst_educpri)
```

### Transit 

```{r}
lst_transit = do_everything(master_sample_wo_na, 'PMS_prox_idx_transit', 2:6)
all_cutoffs_transit = append(all_cutoffs_transit, lst_transit)
```

### Pharma 

```{r}
lst_pharma = do_everything(master_sample_wo_na, 'PMS_prox_idx_pharma', 2:6)
all_cutoffs_pharma = append(all_cutoffs_pharma, lst_pharma)
```

### Education Secondary 

```{r}
lst_educsec = do_everything(master_sample_wo_na, 'PMS_prox_idx_childcare', 2:6)
all_cutoffs_educsec = append(all_cutoffs_educsec, lst_educsec)
```

### Grocery 

```{r}
lst_grocery = do_everything(master_sample_wo_na, 'PMS_prox_idx_grocery', 2:6)
all_cutoffs_grocery = append(all_cutoffs_grocery, lst_grocery)
```

### Library 

```{r}
lst_lib = do_everything(master_sample_wo_na, 'PMS_prox_idx_lib', 2:6)
all_cutoffs_lib = append(all_cutoffs_lib, lst_lib)
```



















