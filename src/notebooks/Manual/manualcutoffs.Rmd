---
title: "Manual cutoffs"
author: "Ricky Heinrich"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = T, message = F, warning = F, fig.height=4, fig.width=6)
library(dplyr)
library(factoextra)
library(ggplot2)
library(tidyverse)
library(gridExtra)
```

```{r}
load('../../../data/master_pms_df.Rdata')

# Convert selected columns to numeric
master <- master %>%
  mutate(PMS_DBPOP = as.numeric(gsub(",", "", PMS_DBPOP)), # Dissemination block population
         PMS_DAPOP = as.numeric(gsub(",", "", PMS_DAPOP)), # Dissemination area population
         PMS_CSDPOP = as.numeric(gsub(",", "", PMS_CSDPOP)), # Census subdivision population
         PMS_CMAPOP = as.numeric(gsub(",", "", PMS_CMAPOP)), # Census metropolitan area population
         PMS_PRPOP = as.numeric(gsub(",", "", PMS_PRPOP)), # Province or territory population
         PMS_prox_idx_emp = as.numeric(PMS_prox_idx_emp),
         PMS_prox_idx_pharma = as.numeric(PMS_prox_idx_pharma),
         PMS_prox_idx_childcare = as.numeric(PMS_prox_idx_childcare),
         PMS_prox_idx_health = as.numeric(PMS_prox_idx_health),
         PMS_prox_idx_grocery = as.numeric(PMS_prox_idx_grocery),
         PMS_prox_idx_educpri = as.numeric(PMS_prox_idx_educpri),
         PMS_prox_idx_educsec = as.numeric(PMS_prox_idx_educsec),
         PMS_prox_idx_lib = as.numeric(PMS_prox_idx_lib),
         PMS_prox_idx_parks = as.numeric(PMS_prox_idx_parks),
         PMS_prox_idx_transit = as.numeric(PMS_prox_idx_transit),
         DBUID = as.character(DBUID),
         PMS_DAUID = as.character(PMS_DAUID),
         PMS_CSDUID = as.character(PMS_CSDUID),
         PMS_CMAUID = as.character(PMS_CMAUID),
         PMS_CMAPUID = as.character(PMS_CMAPUID),
         PMS_PRUID = as.character(PMS_PRUID),
         PMS_suppressed = as.character(PMS_suppressed),
         PMS_transit_na = as.character(PMS_suppressed))


# Subset columns that start with "prox_idx"
amenities <- colnames(master)[grepl("^PMS_prox_idx", colnames(master))]
# master dataset - contains only proximity columns
master_amenities <- master[, amenities]

# subsampling data 
perc = 3 #percentage of data to subsample
subsample = (nrow(master)/100)*perc 
master_sample = master[sample(nrow(master), subsample),] #random sample
```

# Introduction

The Proximity Measures Database contains continuous measures for 10 amenities for a number of DB within a specific threshold. The distribution of these proximity measures is heavily right skewed, and there are for the most part no discernible clusters. The density distribution of each amenity is shown in Figure 1.

```{r fig.height=10, fig.width=6, fig.cap="Distribution of proximity measures by amenity"}
master[,amenities] %>% pivot_longer(all_of(amenities)) %>%
  ggplot(aes(value))+ 
    geom_density() + 
    facet_wrap(~name, scales = 'free_y', ncol = 2) + labs(title = "")
```


When transforming the data, the inherent relationship between data points remain the same, but the new structure may reveal new insights. The most 'famous' transformation available is the log transform. It ["can be used to make highly skewed distributions less skewed"](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Lane)/16%3A_Transformations/16.02%3A_Log_Transformations). It may help "make patterns more visible". A consideration to be aware of is that the log of 0 is -Inf. To account for proximity values of 0 in our dataset, we shift the distribution by +0.0001. This avoids the problem of -Inf whilst maintaining the original distances between all values. The downsides of using a log transformation are [DOWNSIDES]. Figure 2 demonstrates the distribution of the log transformed proximity measures. We can already visually identify more possible clusters. 

```{r eval = F}
# number of 0s per amenity: expecting 1 per amenity
apply(master_amenities , 2 , function(x) sum(na.omit(x == 0)) )

# minimum proximity measure for each amenity: expecting 0
apply(master_amenities , 2 , function(x) min(na.omit(x)) )

# number of 1s per amenity: expecting 1 per amenity
apply(master_amenities , 2 , function(x) sum(na.omit(x == 1)) )
```


```{r eval = F, fig.height=10, fig.width=6, fig.cap="LOG TRANSFORMED: Distribution of proximity measures by amenity"}
master[,amenities] %>% mutate(across(all_of(amenities), ~ .x + 0.001)) %>% log() %>%  pivot_longer(all_of(amenities)) %>%
  ggplot(aes(value))+ 
    geom_density() + 
    facet_wrap(~name, scales = 'free_y', ncol = 2) + labs(title = "")
```

```{r fig.height=10, fig.width=6, fig.cap="LOG TRANSFORMED(0.0001): Distribution of proximity measures by amenity"}
master_log <- master[,amenities] %>% mutate(across(all_of(amenities), ~ .x + 0.0001)) %>% log()
master[,amenities] %>% mutate(across(all_of(amenities), ~ .x + 0.0001)) %>% log() %>%  pivot_longer(all_of(amenities)) %>%
  ggplot(aes(value))+ 
    geom_density() + 
    facet_wrap(~name, scales = 'free_y', ncol = 2) + labs(title = "")
```

```{r eval = F, fig.height=10, fig.width=6, fig.cap="SAMPLED LOG TRANSFORMED Distribution of proximity measures by amenity"}
master_sample_log <- master_sample

# log transform on PMs in master amenities
for (col in amenities){
  master_sample_log[, col] = log(master_sample[, col]+0.001)
}

master_sample_log[,amenities] %>% pivot_longer(all_of(amenities)) %>%
  ggplot(aes(value))+ 
    geom_density() + 
    facet_wrap(~name, scales = 'free_y', ncol = 2) + labs(title = "")
```


A segmentation technique is to segment the distribution at select minima. Each minimum in the density curves represents a density sparse region, which may be a 'natural' break in the continuous measures. 


```{r eval=F}
library(quantmod)
findValleys(d_child$y)
```

```{r eval=F}
find_peaks <- function (x, m = 3){
    shape <- diff(sign(diff(x, na.pad = FALSE)))
    pks <- sapply(which(shape < 0), FUN = function(i){
       z <- i - m + 1
       z <- ifelse(z > 0, z, 1)
       w <- i + m + 1
       w <- ifelse(w < length(x), w, length(x))
       if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(numeric(0))
    })
     pks <- unlist(pks)
     pks
}

# gives index ? of where minimum is
find_peaks(-d_child$y)
```

```{r eval=F}
min_y_vals <- c()
n = 0
for (i in find_peaks(-d_child$y)){
  n = n + 1
  min_y_vals[n] <- d_child$y[i]
}

plot(d_child)
```


```{r fig.cap="Location of Minima and Maxima"}
# for childcare for example
d_child <- density(master_log$PMS_prox_idx_childcare, na.rm = T)

# get locations of Mins and Maxes
DeltaY = diff(d_child$y) # difference in y from x to x+1; same sign as derivative

# if product of consecutive values is negative, that means the sign changed
# essentially remove the first obs, remove the last obs, gives series with same size, but shifted by one
# when multiply together, multiplying consecutive values
Turns = which(DeltaY[-1] * DeltaY[-length(DeltaY)] < 0) + 1 # turning points where sign changed

# if turn point is negative, then maximum
# if turn point is positive, then minimum
lst_max <- c()
lst_min <- c()
for (i in Turns){
  
  if (DeltaY[i]<0) {
    lst_max <- append(lst_max, i)
  }
  if (DeltaY[i]>0){
    lst_min <- append(lst_min, i)
  }
}

# plot mins and maxes on density plot
plot(d_child, xlab="", ylab="", main="")
points(d_child$x[lst_max], d_child$y[lst_max], pch=16, col="blue")
points(d_child$x[lst_min], d_child$y[lst_min], pch=16, col="red")
legend(x="topright", legend = c("Minima","Maxima"), col = c("blue","red"), pch = 16)

```
```{r}

```


```{r eval=F}
# reproduce on all plots
p <- list() # list of plots
for (amen in amenities){
  
}


most = 0
for(i in amenities){
  temp = na.omit(master[,i]) # select only amenity i col
  dt <- data.table(x=1:length(temp),y=temp) # make data.table with x = index, y = value
  dens <- density(dt$y) # get density values
  df <- data.frame(x=dens$x, y=dens$y) # data frame
  # cutoff = chdbscan[[i]] #change this for different algorithms!
  # logged <- log(cutoff+0.0001)
  df$Cluster <- as.factor(as.numeric(cut(df$x, c(min(df$x), logged, max(df$x)),  include.lowest=T)))
  plt = ggplot(df, aes(x,y)) + geom_line() + geom_ribbon(aes(ymin=0, ymax=y, fill=Cluster)) + 
    #scale_x_continuous(breaks=round(logged, 2)) + 
    ylab('') + guides(fill = 'none') + 
    theme(
      #axis.text.x = element_text(angle = 45, vjust = 0.8, hjust=1, size=8), 
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(),
      plot.margin=unit(c(0,0,0.1,0),"cm"),
      plot.title = element_text(size = 10),
      axis.ticks.y = element_blank(),
      axis.text.y = element_blank(),
      axis.text.x = element_blank(), #removes x axis labels
      axis.ticks.x = element_blank() #removes x axis ticks
      ) +
    ggtitle(str_sub(i, 14))
  if (is.null(cutoff[1])){
    plt = plt + xlab("NO CLUSTERS DETECTED") + theme(axis.title.x = element_text(size = 7, color='gray'))
  } else {
    plt = plt + xlab(paste(round(cutoff, 3), collapse = ', ')) + theme(axis.title.x = element_text(size = 7, color='gray'))
  }
  # add plot to list
  p[[i]] = plt
  
  # set legend
  # if (length(cutoff) > most){
  #   most = length(cutoff)
  #   most_plt = ggplot(df, aes(x,y)) + geom_line() + geom_ribbon(aes(ymin=0, ymax=y, fill=Cluster)) +
  #     scale_x_continuous(breaks=round(logged, 2)) +
  #     guides(fill = guide_legend(title.position = "top", label.hjust = 0.5)) +
  #     theme(
  #       legend.direction = "horizontal"
  #     )
  #}
}

# most = names(lapply(chdbscan, length)[lapply(chdbscan, length) == max(unlist(lapply(chdbscan, length)))][1])
# p[[11]] = g_legend(most_plt)

layout_mat <- rbind(c(1:4),
                    c(5:8),
                    c(9:11, 11))
cutoffs = do.call(grid.arrange,list(grobs=p, layout_matrix=layout_mat))
```


