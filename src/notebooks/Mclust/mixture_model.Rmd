---
title: "MixAll_updated"
author: "PMS"
date: "2023-05-29"
output:
  pdf_document:
    dev: png
urlcolor: blue
---

```{r global_options, include=FALSE}
## Set some options for knitr to apply globally
knitr::opts_chunk$set(cache=TRUE,
                      echo=FALSE,
                      autodep=TRUE,
                      message=FALSE,
                      warning=FALSE,
                      out.width="80%",
                      fig.asp=0.75,
                      fig.align='center',
                      fig.pos = "H", 
                      out.extra = "")
```

```{r}
library(dplyr)
library(MixAll)
library(cluster)
library(factoextra)
library(mclust)

library(fpc)
library(clusterSim)
library(clusterCrit)

load('../../../data/master_pms_df.Rdata')
# head(master, 5)
```

### subsampling data

```{r, cache=TRUE, echo=TRUE}
# covert populations to numeric from factor
master$PMS_DBPOP = as.numeric(gsub("[^0-9.-]", "", as.character(master$PMS_DBPOP)))
master$PMS_CSDPOP = as.numeric(gsub("[^0-9.-]", "", as.character(master$PMS_CSDPOP)))

# subsampling 
perc = 3 #percentage of data to subsample
subsample = (nrow(master)/100)*perc 
pms_subsample = master[sample(nrow(master), subsample),]

ammenities <- c("PMS_prox_idx_emp", "PMS_prox_idx_pharma", "PMS_prox_idx_childcare", "PMS_prox_idx_health", "PMS_prox_idx_grocery", "PMS_prox_idx_educpri", "PMS_prox_idx_educsec", "PMS_prox_idx_lib", "PMS_prox_idx_parks", "PMS_prox_idx_transit")

pms_prox <- pms_subsample[, ammenities]
```

### subsampling data

```{r, cache=TRUE, echo=TRUE}
# results_df <- data.frame()
# 
# for (amenity in ammenities) {
#   
#   for (num_clusters in 2:8) {
#     # each amenity
#     pms_amen <- pms_prox[, amenity]
#     pms_amen <- na.omit(pms_amen)
#     pms_amen_log <- log(pms_amen + 0.0001)
#     
#     # cluster data
#     model <- Mclust(pms_amen_log, G = num_clusters)
#     clus_labels = model$classification
#     clus_data <- model$data
#     
#     # calculate metrics
#     dunn_stats <- cluster.stats(dist(clus_data), clus_labels)
#     calinski_harabasz <- calinhara(clus_data, clus_labels)
#     xie_beni <- intCriteria(as.matrix(clus_data), as.integer(clus_labels), 'Xie_Beni')$xie_beni
#     davies_bouldin <- index.DB(clus_data, clus_labels)
#     sil_coef = intCriteria(as.matrix(clus_data), as.integer(clus_labels),'Silhouette')$silhouette
#     
#     # df containing each ammenity, # of clusters, and metric score
#     amenity_df <- data.frame(
#       amenity = amenity,
#       num_clusters = num_clusters,
#       dunn = dunn_stats$dunn,
#       calinski_harabasz = calinski_harabasz,
#       xie_beni = xie_beni,
#       davies_bouldin = davies_bouldin$DB,
#       sil_coef = sil_coef
#     )
#     
#     results_df <- rbind(results_df, amenity_df)
#   }
# }
# 
# head(results_df, 7)
```

### Cutoff function

```{r, cache=TRUE}
compute_cutoffs <- function(data, labels) {
    unique_labels <- sort(unique(labels))
    cutoffs <- numeric(length(unique_labels) - 1)
    for (i in 1:(length(unique_labels) - 1)) {
        cluster1 <- data[which(labels == unique_labels[i])]
        cluster2 <- data[which(labels == unique_labels[i + 1])]
        cutoffs[i] <- median(c(max(cluster1), min(cluster2)))
    }
    return(cutoffs)
}
```

### number of clusters function

```{r}
optimal_num_clusters <- function(amenity, results_df) {
  #filter by ammenity
  amenity_df <- results_df[results_df$amenity == amenity, ]
  
  # count agreements for each number of clusters
  agreement_scores <- numeric(8)  
  for (num_clusters in 2:8) {
    agreement_scores[num_clusters] <- sum(
      amenity_df$num_clusters[which.max(amenity_df$dunn)] == num_clusters,
      amenity_df$num_clusters[which.max(amenity_df$sil_coef)] == num_clusters,
      amenity_df$num_clusters[which.min(amenity_df$davies_bouldin)] == num_clusters,
      amenity_df$num_clusters[which.min(amenity_df$xie_beni)] == num_clusters,
      amenity_df$num_clusters[which.max(amenity_df$calinski_harabasz)] == num_clusters
    )
  }
  
  # Find number of clusters with highest agreement score
  best_num_clusters <- which.max(agreement_scores)
  
  return(best_num_clusters)
}
```

### getting cutoffs and metrics for optimal cluster

```{r, cache=TRUE, echo=TRUE}
sil_mixall <- c()
dunn_mixall <- c()
xei_beni_mixall <- c()
calinski_harabasz_mixall <- c()
davies_bouldin_mixall <- c()
num_of_clust_mixall <- c()

cut_offs_mixall <- list()

for (amenity in ammenities) {

  # select the best number of clusters for current amenity
  # num_clusters <- optimal_num_clusters(amenity, results_df)

  pms_amen <- pms_prox[, amenity]
  pms_amen <- na.omit(pms_amen)
  pms_amen_log <- log(pms_amen + 0.0001)

  # cluster data
  model <- Mclust(pms_amen_log)

  clus_labels = model$classification
  clus_data <- model$data
  num_clusters <- model$G

  # compute metrics and cutoffs for storing later on
  dunn_stats <- cluster.stats(dist(clus_data), clus_labels)
  calinski_harabasz <- calinhara(clus_data, clus_labels)
  xie_beni <- intCriteria(as.matrix(clus_data), as.integer(clus_labels), 'Xie_Beni')$xie_beni
  davies_bouldin <- index.DB(clus_data, clus_labels)
  sil_coef <- intCriteria(as.matrix(clus_data), as.integer(clus_labels),'Silhouette')$silhouette
  cutoffs <- compute_cutoffs(clus_data, clus_labels)

  # store the metrics
  sil_mixall <- c(sil_mixall, sil_coef)
  dunn_mixall <- c(dunn_mixall, dunn_stats$dunn)
  xei_beni_mixall <- c(xei_beni_mixall, xie_beni)
  calinski_harabasz_mixall <- c(calinski_harabasz_mixall, calinski_harabasz)
  davies_bouldin_mixall <- c(davies_bouldin_mixall, davies_bouldin$DB)
  num_of_clust_mixall <- c(num_of_clust_mixall, num_clusters)
  cut_offs_mixall[[amenity]] <- cutoffs
}

```

```{r, echo=TRUE}
sil_mixall
```

```{r, echo=TRUE}
dunn_mixall
```

```{r, echo=TRUE}
xei_beni_mixall
```

```{r, echo=TRUE}
calinski_harabasz_mixall
```

```{r, echo=TRUE}
davies_bouldin_mixall
```

```{r, echo=TRUE}
num_of_clust_mixall
```

```{r, echo=TRUE}
cut_offs_mixall
```

